{"cells":[{"cell_type":"code","source":["# Sentiment analysis (Binary classification) - Without embedding layer\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","\n","#Load IMDB Dataset\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n","\n","#IMDB has different lengths, but dense expects a fixed number of neurons\n","# We are ensuring every input is exactly 200 words\n","\n","# Pad sequence to ensure fixed length of i/p\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","x_train = pad_sequences(x_train, maxlen=200)\n","x_test = pad_sequences(x_test, maxlen=200)\n","\n","# Build model using only dense layers\n","model = models.Sequential([\n","    layers.Flatten(input_shape=(200,)), # Convert 2D sequences to 1D\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(1, activation='sigmoid') #Binary Classification\n","])\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train model\n","model.fit(x_train, y_train, epochs=5, batch_size=512)\n","\n","# Evaluate model\n","test_loss, test_accuracy = model.evaluate(x_test, y_test)\n","print(f\"Test accuracy: {test_accuracy * 100:.2f}\")\n","\n","# Make a prediction on the first test sample\n","predicted_sentiment = model.predict(x_test[0:1])\n","print(\"Predicted Sentiment:\", \"Positive\" if predicted_sentiment[0][0] > 0.5 else \"Negative\")"],"metadata":{"id":"vQNCvarEj0q6","executionInfo":{"status":"ok","timestamp":1761736591681,"user_tz":-330,"elapsed":12623,"user":{"displayName":"","userId":""}},"outputId":"ddff395a-101a-4f31-c93a-6b2e42b05d63","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5069 - loss: 248.4091\n","Epoch 2/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5342 - loss: 81.9710\n","Epoch 3/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5569 - loss: 47.1498\n","Epoch 4/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5758 - loss: 29.8093\n","Epoch 5/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6003 - loss: 21.1953\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5101 - loss: 32.1921\n","Test accuracy: 50.69\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n","Predicted Sentiment: Positive\n"]}]},{"cell_type":"code","source":["# Sentiment analysis - Embedding\n"," # Sentiment analysis (Binary classification)\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","\n","#Load IMDB Dataset\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n","\n","#IMDB has different lengths, but dense expects a fixed number of neurons\n","# We are ensuring every input is exactly 200 words\n","\n","# Pad sequence to ensure fixed length of i/p\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","x_train = pad_sequences(x_train, maxlen=200)\n","x_test = pad_sequences(x_test, maxlen=200)\n","\n","# Build model using only dense layers\n","model = models.Sequential([\n","    layers.Embedding(input_dim=10000, output_dim=128, input_length=200),\n","    layers.Flatten(input_shape=(200,)), # Convert 2D sequences to 1D\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(1, activation='sigmoid') #Binary Classification\n","])\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train model\n","model.fit(x_train, y_train, epochs=5, batch_size=512)\n","\n","# Evaluate model\n","test_loss, test_accuracy = model.evaluate(x_test, y_test)\n","print(f\"Test accuracy: {test_accuracy * 100:.2f}\")\n","\n","# Make a prediction on the first test sample\n","# predicted_sentiment = model.predict(x_test[0:1])\n","# print(\"Predicted Sentiment:\", \"Positive\" if predicted_sentiment[0][0] > 0.5 else \"Negative\")"],"metadata":{"id":"2nGc2isFkGRE","executionInfo":{"status":"ok","timestamp":1761738206669,"user_tz":-330,"elapsed":196402,"user":{"displayName":"","userId":""}},"outputId":"0e6d65a0-b34a-41d3-94b7-b7adde708e3f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 599ms/step - accuracy: 0.6054 - loss: 0.6336\n","Epoch 2/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 537ms/step - accuracy: 0.9351 - loss: 0.1814\n","Epoch 3/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 513ms/step - accuracy: 0.9946 - loss: 0.0339\n","Epoch 4/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 487ms/step - accuracy: 0.9993 - loss: 0.0052\n","Epoch 5/5\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 9.2001e-04\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8538 - loss: 0.5327\n","Test accuracy: 85.52\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n","Predicted Sentiment: Negative\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xT6_wFpVFPlr"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to Colab","provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1761828481306}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}